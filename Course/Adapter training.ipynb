{"cells":[{"cell_type":"markdown","id":"e7461da0","metadata":{"id":"e7461da0"},"source":["## Instalar pysentimiento y AdapterHub"]},{"cell_type":"markdown","source":["Las dos celdas de código en este apartado se tienen que **ejecutar en el orden en que están**, de otro modo habrá errores. Esto se debe a una incompatibilidad entre pysentimiento y AdapterHub."],"metadata":{"id":"E0h3znEZ7jE7"},"id":"E0h3znEZ7jE7"},{"cell_type":"markdown","source":["El paquete **pysentimiento** es necesario para preprocesar el texto cuando se quiere utilizar el modelo preentrenado RoBERTuito. Se trata de un caso aislado, con otros modelos se puede usar directamente el tokenizador."],"metadata":{"id":"sILY8zXn62fJ"},"id":"sILY8zXn62fJ"},{"cell_type":"code","source":["!pip install pysentimiento"],"metadata":{"id":"1WJ4lZJU6uWI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666714626758,"user_tz":300,"elapsed":18452,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"3ac4bc08-80f6-4035-8c7a-f202a03d37b5"},"id":"1WJ4lZJU6uWI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pysentimiento\n","  Downloading pysentimiento-0.4.2-py3-none-any.whl (30 kB)\n","Collecting transformers==4.13\n","  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 49.9 MB/s \n","\u001b[?25hCollecting emoji<2.0.0,>=1.6.1\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 71.1 MB/s \n","\u001b[?25hCollecting sklearn<0.1,>=0.0\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting datasets<2.0.0,>=1.13.3\n","  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 60.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pysentimiento) (1.12.1+cu113)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 67.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 57.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13->pysentimiento) (21.3)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 53.5 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2022.8.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (3.8.3)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 71.3 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.3.5.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.8.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.1.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (0.13.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13->pysentimiento) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13->pysentimiento) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 76.0 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn<0.1,>=0.0->pysentimiento) (1.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13->pysentimiento) (3.9.0)\n","Collecting dill\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[K     |████████████████████████████████| 110 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2022.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13->pysentimiento) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (1.7.3)\n","Building wheels for collected packages: emoji, sklearn, sacremoses\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=8ad07e984a3e8f8a787f410efbb4118ece9b92698d613e390e3238351b3341ac\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=80b004de3daff914b8c4cc7b3f809ab24bb51c0e1a2d12f5259bb3bb6165b04f\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=36f3ed3b17e4da43297616d3a1f55ab9ef775374d1d0b8c103422710e5236667\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built emoji sklearn sacremoses\n","Installing collected packages: urllib3, dill, xxhash, tokenizers, sacremoses, responses, multiprocess, huggingface-hub, transformers, sklearn, emoji, datasets, pysentimiento\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","Successfully installed datasets-1.18.4 dill-0.3.6 emoji-1.7.0 huggingface-hub-0.10.1 multiprocess-0.70.14 pysentimiento-0.4.2 responses-0.18.0 sacremoses-0.0.53 sklearn-0.0 tokenizers-0.10.3 transformers-4.13.0 urllib3-1.25.11 xxhash-3.1.0\n"]}]},{"cell_type":"markdown","source":["La siguiente línea es para descargar e instalar **AdapterHub**. Debido a la incompatibilidad con pysentimiento, al terminar la instalación es posible que imprima algunos errores de incompatibilidad."],"metadata":{"id":"yRtgvDOU7R57"},"id":"yRtgvDOU7R57"},{"cell_type":"code","source":["!pip install adapter-transformers"],"metadata":{"id":"bDYB-idd6ui4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666714645044,"user_tz":300,"elapsed":13173,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"7c956809-cc78-4470-93b6-d675a8cb6541"},"id":"bDYB-idd6ui4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting adapter-transformers\n","  Downloading adapter_transformers-3.1.0-py3-none-any.whl (4.8 MB)\n","\u001b[K     |████████████████████████████████| 4.8 MB 31.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.13.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (0.10.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->adapter-transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->adapter-transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->adapter-transformers) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (3.0.4)\n","Installing collected packages: tokenizers, adapter-transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.10.3\n","    Uninstalling tokenizers-0.10.3:\n","      Successfully uninstalled tokenizers-0.10.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","transformers 4.13.0 requires tokenizers<0.11,>=0.10.1, but you have tokenizers 0.12.1 which is incompatible.\u001b[0m\n","Successfully installed adapter-transformers-3.1.0 tokenizers-0.12.1\n"]}]},{"cell_type":"markdown","source":["Cuando la celda anterior termine de ejecutarse **deberá reiniciarse el entorno de ejecución**. Para ello, ir a la pestaña *Entorno de ejecución* y seleccionar opción *Reiniciar entorno de ejecución*. Una vez reiniciado el entorno, **ejecutar a partir del apartado de Librerías**."],"metadata":{"id":"HsBbPu5U8LN6"},"id":"HsBbPu5U8LN6"},{"cell_type":"markdown","source":["## Librerías"],"metadata":{"id":"_t4QVIPf6uA4"},"id":"_t4QVIPf6uA4"},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import os"],"metadata":{"id":"7tgSaKlI5j_7"},"id":"7tgSaKlI5j_7","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Descargar datos"],"metadata":{"id":"cb9_4fq8m_Gv"},"id":"cb9_4fq8m_Gv"},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=1GSrykEbhF9kJMfhj3Bkm0BiVkjoznR9i"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8x1mDUI5Ln8","executionInfo":{"status":"ok","timestamp":1666714863750,"user_tz":300,"elapsed":4371,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"8cc1f31c-e59d-416f-e48e-9a9b027bf80b"},"id":"u8x1mDUI5Ln8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1GSrykEbhF9kJMfhj3Bkm0BiVkjoznR9i\n","To: /content/dataMEXA3.zip\n","\r  0% 0.00/300k [00:00<?, ?B/s]\r100% 300k/300k [00:00<00:00, 128MB/s]\n"]}]},{"cell_type":"code","source":["!unzip dataMEXA3.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9CXAmBkK5LwD","executionInfo":{"status":"ok","timestamp":1666714867287,"user_tz":300,"elapsed":339,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"16bf2517-4529-4e7a-8ccd-fdf6273d7ab0"},"id":"9CXAmBkK5LwD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  dataMEXA3.zip\n","   creating: dataMEXA3/\n","  inflating: dataMEXA3/mex20_test_full.txt  \n","  inflating: dataMEXA3/mex20_train.txt  \n","  inflating: dataMEXA3/mex20_train_labels.txt  \n","  inflating: dataMEXA3/mex20_val.txt  \n","  inflating: dataMEXA3/mex20_val_labels.txt  \n"]}]},{"cell_type":"markdown","id":"523b894b","metadata":{"id":"523b894b"},"source":["## Dataset"]},{"cell_type":"markdown","source":["La clase mexA3 se crea con tres parámetros:\n","\n","*   Directorio donde se encuentran todos los datos\n","*   Split que se utilizará (train o val)\n","*   El tokenizador\n","\n","La función preprocess_tweet sirve para preprocesar el texto del tweet antes de ser tokenizado (exclusivo de RoBERTuito)."],"metadata":{"id":"tpr7Fs4fnYFa"},"id":"tpr7Fs4fnYFa"},{"cell_type":"code","execution_count":null,"id":"59ae24f8","metadata":{"id":"59ae24f8"},"outputs":[],"source":["# CREATE DATASET CLASS---------------------------------------------------------------------------------------------\n","\n","import os\n","from torch.utils.data import Dataset\n","from pysentimiento.preprocessing import preprocess_tweet\n","\n","class mexA3(Dataset):\n","    \n","    def __init__(self, Dir, split, tokenizer, use_labels = True):\n","        self.use_labels = use_labels\n","        \n","        if split != 'test':\n","            text_file   = os.path.join(Dir, 'mex20_' + split + '.txt')\n","        else:\n","            text_file   = os.path.join(Dir, 'mex20_' + split + '_full.txt')\n","        self.text      = [line      for line in open(text_file)]\n","            \n","        labels_file = os.path.join(Dir, 'mex20_' + split + '_labels.txt')\n","        if use_labels:\n","            self.labels    = [int(line) for line in open(labels_file)]\n","        \n","        preprocessed   = [preprocess_tweet(tweet) for tweet in self.text]\n","        self.encodings = tokenizer(preprocessed, max_length = 128, truncation = True, padding = True)\n","        \n","    def __len__(self):\n","        return len(self.text)\n","    \n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        #item['text']   = self.text[idx]\n","        if self.use_labels:\n","            item['labels'] = torch.tensor(self.labels[idx])#torch.tensor([self.labels[idx]])\n","        return item\n","        "]},{"cell_type":"markdown","source":["Ahora se carga el tokenizador preentrenado de RoBERTuito, usando la clase AutoTokenizer"],"metadata":{"id":"c_5KXz8nnaJx"},"id":"c_5KXz8nnaJx"},{"cell_type":"code","execution_count":null,"id":"83fe9968","metadata":{"id":"83fe9968","executionInfo":{"status":"ok","timestamp":1666714895938,"user_tz":300,"elapsed":10719,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["85d0faef4adf455380bad14a3131b325","ad5db37da70c4d01ba59e24503399176","4753eb1187f8455b891b3b544c40bb1a","42c6777a177a47a0b3989159ea8b1272","326b02c8d0f047e4afd2112fd490fd11","13682ba38f3c467cbd7fc4bdd3361dee","23d40e8793204e059d2f8abd32fd2cf4","ca848dfefc164cffab3e9167bed53ed7","268f3a01442b4ca0ac9d34ceace67abc","1a97dda7c3cc49a8b8027cbdc6740eb0","2fddb6db0aba440e8d123fecec44b414","428be957f35849178b007e15a8dc0ff5","13098c6d454844ac839b6488dc456b02","6f7707a781244d2fa45e950619bd6c9c","239bc939116d4f76bd9ee0edf8e0e89b","1b2c33a654fe4e66a7e78f53f53f8fb1","feb8ed226bcc4d5b9d783ec709cbd587","383847178bfd44b9a73f3af4af38f5e9","c0b0697bf78c4b7b9233f0202577ae50","2b93ef335afe4439bbe76375d92dcc31","cbeaf5e149814ceda60909b9f8c1d91b","08ebe1f7dd1444879ee0d055cf111442","1a1e9c3c181448fcae101a45b0a78c2b","819ee85041b24d2dab4ae7d3e835f624","26e9f2fe86b947f38f844cdbfcdf278a","3a142204fc1144c7b18c898123296bc1","e8a4093d6ae446caa295d49fc45065df","8c590549070f41da84e555e0a19e4cd8","5b738913fc4f4db1b53f9c85c497ec54","e65dd185ea4747a3b61ce3096ce8a354","d422c7c15859441683d8dcd43b44267f","a89d4c32c3d44d209373daef7c222a6e","03948ec542a443f4b050695443eee569"]},"outputId":"7cd48619-412c-4c7f-d75e-e10e60991d88"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d0faef4adf455380bad14a3131b325"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/809k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428be957f35849178b007e15a8dc0ff5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1e9c3c181448fcae101a45b0a78c2b"}},"metadata":{}}],"source":["# GET TOKENIZER, VOCAB AND DIR OF DATASET--------------------------------------------------------------------------\n","\n","from transformers import AutoTokenizer\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained('pysentimiento/robertuito-base-cased')\n","Dir       = \"dataMEXA3\"\n","vocab     = tokenizer.get_vocab()\n","\n","id2w = {}\n","for w in vocab:\n","    id2w[vocab[w]] = w"]},{"cell_type":"markdown","source":["Finalmente, se crean las instancias de los datasets train y val"],"metadata":{"id":"gFVEfNZ-narS"},"id":"gFVEfNZ-narS"},{"cell_type":"code","execution_count":null,"id":"b7ef24e2","metadata":{"id":"b7ef24e2"},"outputs":[],"source":["train_dataset = mexA3(Dir, 'train', tokenizer)\n","val_dataset   = mexA3(Dir, 'val'  , tokenizer)"]},{"cell_type":"markdown","id":"66e9e282","metadata":{"id":"66e9e282"},"source":["## Modelo"]},{"cell_type":"markdown","source":["Así como en HuggingFace se tiene la clase AutoModel, análogamente, en AdapterHub se tiene la clase AutoAdapterModel, con el que se puede cargar un modelo pre-entrenado de HuggingFace sin especificar la arquitectura, con la diferencia de que ya tiene todos los métodos para el uso de adapters incluidos"],"metadata":{"id":"Y-0bqMKsnnB7"},"id":"Y-0bqMKsnnB7"},{"cell_type":"code","execution_count":null,"id":"36486f36","metadata":{"id":"36486f36","outputId":"7530074b-6d93-419f-fd4b-47a99a2eb8ee","colab":{"base_uri":"https://localhost:8080/","height":192,"referenced_widgets":["c1953d9d4c464000b0dfec3fd8b66304","9d18d11987184fe28cae708448c6dbfa","f572333da8ac4278997b9372ab2e1932","31d47c29f763463b9707146d9b491acc","6acb0bae6c314a4f8c69abc506a41a17","e71849750e8b465d939b3273665a4080","f3e8e8f4fb4343868d27c746d8c7067c","daaa9b3d39f5450c9476960cd6c562c6","e2520436aa754218839173ae6f6d5e1f","8404632412c1400fa678d791f28137c3","3ad4dd9eaef544ecbe9ef5e42be1b93a","e080df9208474471956cac43ed054af0","88df4bb14317408387f6d5fe41b99290","761127450eaf46528199ba82841d838c","b30c938b336d4bf4b40b7f05a839ba80","74030870d8e34811acbf685515bd0c8c","e51ca81da6fe4fffb96b2c17d15a2bd2","161b24c20e6b4694b682a7f0e0cc0085","0663f9f459414d4fa4bcb08539941a18","ba7dd565ccf944ffa3b0c23559a7f313","fbdc455551124373ba7eab5fb0796b47","2745d2c26cf545428661d86e030a843e"]},"executionInfo":{"status":"ok","timestamp":1666714995469,"user_tz":300,"elapsed":47762,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1953d9d4c464000b0dfec3fd8b66304"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/415M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e080df9208474471956cac43ed054af0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at pysentimiento/robertuito-base-cased were not used when initializing RobertaAdapterModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaAdapterModel were not initialized from the model checkpoint at pysentimiento/robertuito-base-cased and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoAdapterModel\n","\n","model = AutoAdapterModel.from_pretrained(\"pysentimiento/robertuito-base-cased\")\n"]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKnEXL278-Q4","executionInfo":{"status":"ok","timestamp":1666714997047,"user_tz":300,"elapsed":8,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"357cf712-c8ea-4dc5-e0c9-5b50728488eb"},"id":"DKnEXL278-Q4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaAdapterModel(\n","  (shared_parameters): ModuleDict()\n","  (roberta): RobertaModel(\n","    (shared_parameters): ModuleDict()\n","    (invertible_adapters): ModuleDict()\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(130, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict()\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","    (prefix_tuning): PrefixTuningPool(\n","      (prefix_tunings): ModuleDict()\n","    )\n","  )\n","  (heads): ModuleDict()\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","id":"dd3a3b90","metadata":{"id":"dd3a3b90"},"source":["## Adapter"]},{"cell_type":"markdown","source":["Los modelos soportados por AdapterHub tienen el método \"add_adapter\"\" que sirve para añadir un adapter al modelo. Principalmente tiene  dos parámetros:\n","\n","*   **adapter_name: [string]** ,    usualmente nombre de la tarea que resuelve\n","*   **config: [str, dict, AdapterConfig]** ,    la arquitectura del adapter. \n","\n","AdapterHub soporta diferentes arquitecturas para adapters de artículos recientes. Hay algunas configuraciones pre-establecidas como: PfeifferConfig(default), HoulsbyConfig, ParallelConfig, etc.. También hay alrededor de 400 adapters pre-entrenados que se pueden utilizar.\n","\n","Cada **adapter** debe tener una **etiqueta de tipo string**, para referirse a él en el futuro, ya que un mismo modelo base puede tener más de un adapter. Si el adapter se utilizará para clasificación, debe añadirse también su respectiva **cabeza de clasificación con la misma etiqueta**."],"metadata":{"id":"yZML3HZ6n_S_"},"id":"yZML3HZ6n_S_"},{"cell_type":"code","execution_count":null,"id":"8aa6651a","metadata":{"id":"8aa6651a"},"outputs":[],"source":["# name of the task\n","task_name = \"mexA3\"\n","\n","# Add a new adapter\n","from transformers import ParallelConfig\n","\n","model.add_adapter(\n","    adapter_name = task_name, \n","    config       = ParallelConfig()\n",")\n","\n","# Add a matching classification head\n","model.add_classification_head(\n","    head_name  = task_name,\n","    num_labels = 2,\n","    id2label   = { 0: \"Neutro\", 1: \"Agresivo\"}\n",")"]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vURhHqq_-djP","executionInfo":{"status":"ok","timestamp":1666715347245,"user_tz":300,"elapsed":321,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"234ab8ed-58bf-4526-a602-ae761257afdf"},"id":"vURhHqq_-djP","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaAdapterModel(\n","  (shared_parameters): ModuleDict()\n","  (roberta): RobertaModel(\n","    (shared_parameters): ModuleDict()\n","    (invertible_adapters): ModuleDict()\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(130, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (key): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (value): Linear(\n","                in_features=768, out_features=768, bias=True\n","                (loras): ModuleDict()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (prefix_tuning): PrefixTuningShim(\n","                (prefix_gates): ModuleDict()\n","                (pool): PrefixTuningPool(\n","                  (prefix_tunings): ModuleDict()\n","                )\n","              )\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (adapters): ModuleDict()\n","              (adapter_fusion_layer): ModuleDict()\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(\n","              in_features=768, out_features=3072, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(\n","              in_features=3072, out_features=768, bias=True\n","              (loras): ModuleDict()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (adapters): ModuleDict(\n","              (mexA3): ParallelAdapter(\n","                (non_linearity): Activation_Function_Class(\n","                  (f): ReLU()\n","                )\n","                (adapter_down): Sequential(\n","                  (0): Linear(in_features=768, out_features=384, bias=True)\n","                  (1): Activation_Function_Class(\n","                    (f): ReLU()\n","                  )\n","                )\n","                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n","              )\n","            )\n","            (adapter_fusion_layer): ModuleDict()\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","    (prefix_tuning): PrefixTuningPool(\n","      (prefix_tunings): ModuleDict()\n","    )\n","  )\n","  (heads): ModuleDict(\n","    (mexA3): ClassificationHead(\n","      (0): Dropout(p=0.1, inplace=False)\n","      (1): Linear(in_features=768, out_features=768, bias=True)\n","      (2): Activation_Function_Class(\n","        (f): Tanh()\n","      )\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Linear(in_features=768, out_features=2, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Hasta este punto, ya se añadió un adapter y una cabeza de clasificación. Sin embargo, como se puede ver en las siguientes celdas, todos los parámetros son entrenables. "],"metadata":{"id":"ctVJy-5P-ppS"},"id":"ctVJy-5P-ppS"},{"cell_type":"code","source":["def trainable_parameters_relation(model):\n","  total_params = 0\n","  train_params = 0\n","  for name, param in model.named_parameters():\n","    curr = np.array(param.shape).prod()\n","    total_params += curr\n","    if param.requires_grad:\n","      #print(name)\n","      train_params += curr\n","  \n","  return 100*train_params/total_params"],"metadata":{"id":"3DiX1TQu9puy"},"id":"3DiX1TQu9puy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nParametros entrenables:\", trainable_parameters_relation(model), \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeg-z5rV9qQq","executionInfo":{"status":"ok","timestamp":1666715388041,"user_tz":300,"elapsed":317,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"62a68171-1ed7-47cf-88b8-3f9b931bd640"},"id":"zeg-z5rV9qQq","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Parametros entrenables: 100.0 %\n"]}]},{"cell_type":"markdown","source":["En la siguiente celda se aplican dos operaciones:\n","\n","\n","*   La primera sirve para activar el adapter que vamos a utilizar, lo que obliga a que el input use las capas asociadas al adapter y a la cabeza de clasificación.\n","*   La segunda línea es NECESARIA para entrenar el adapter. Una de sus funciones es congelar los pesos del modelo base.\n","\n"],"metadata":{"id":"Qam1NnEf-_XA"},"id":"Qam1NnEf-_XA"},{"cell_type":"code","source":["# Activate the adapter\n","model.set_active_adapters(task_name)\n","model.train_adapter(task_name)"],"metadata":{"id":"PkBxZUaa9v-i"},"id":"PkBxZUaa9v-i","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se verifica nuevamente el procentaje de parámetros entrenables."],"metadata":{"id":"l-1p5Qac_3q6"},"id":"l-1p5Qac_3q6"},{"cell_type":"code","source":["print(\"\\nParametros entrenables:\", trainable_parameters_relation(model), \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lShHE9P_98q","executionInfo":{"status":"ok","timestamp":1666715449720,"user_tz":300,"elapsed":328,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"531ae73e-ba1a-4c34-de20-c2a53d3864f1"},"id":"9lShHE9P_98q","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Parametros entrenables: 6.597212378335209 %\n"]}]},{"cell_type":"markdown","id":"df2d64c4","metadata":{"id":"df2d64c4"},"source":["## Entrenamiento"]},{"cell_type":"markdown","source":["HuggingFace cuenta con una clase llamada Trainer, que sirve para entrenar sus modelos de forma sencilla en los casos más estándar (como en este caso, clasificación). \n","\n","Antes de crear una instancia de Trainer, es necesario definir los parámetros que se utilizarán para el entrenamiento. Para ello, hay que crear una instancia de la clase TrainingArguments.\n","\n","**Algunas ventajas**: cuida que el modelo y los datos estén en el mismo dispositivo (gpu, cpu) y, si hay más de 1 gpu, utiliza todos para hacer el entrenamiento en paralelo."],"metadata":{"id":"S8hHvjc0oC__"},"id":"S8hHvjc0oC__"},{"cell_type":"code","execution_count":null,"id":"55155266","metadata":{"id":"55155266"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    learning_rate               = 1e-4,\n","    #weight_decay                 = 0.01,\n","    num_train_epochs            = 5,\n","    per_device_train_batch_size = 32,\n","    per_device_eval_batch_size  = 32,\n","    logging_steps               = 100,\n","    output_dir                  = \"./training_output\",\n","    overwrite_output_dir        = True,\n","    # The next line is important to ensure the dataset labels are properly passed to the model\n","    remove_unused_columns       = False,\n",")"]},{"cell_type":"markdown","source":["Análogamente, AdapterHub tiene la clase AdapterTrainer, que está pensada para entrenar únicamente adapters. Se utiliza igual que Trainer. \n","\n","Una de las ventajas es que si los pesos del modelo base no están congelados, al intentar entrenar con AdapterTrainer arrojará error."],"metadata":{"id":"4yWTeky2oRXh"},"id":"4yWTeky2oRXh"},{"cell_type":"code","source":["from transformers import AdapterTrainer, EvalPrediction\n","\n","def compute_accuracy(p: EvalPrediction):\n","  preds = np.argmax(p.predictions, axis=1)\n","  return {\"acc\": (preds == p.label_ids).mean()}\n","\n","trainer = AdapterTrainer(\n","    model           = model,\n","    args            = training_args,\n","    train_dataset   = train_dataset,\n","    eval_dataset    = val_dataset,\n","    compute_metrics = compute_accuracy,\n",")\n","trainer.args._n_gpu = 1"],"metadata":{"id":"fCIik9PJoJYR"},"id":"fCIik9PJoJYR","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"cc52754e","metadata":{"id":"cc52754e","outputId":"6444292d-f4b7-4c1a-90d7-2b73256d6be6","colab":{"base_uri":"https://localhost:8080/","height":746},"executionInfo":{"status":"ok","timestamp":1666145736716,"user_tz":300,"elapsed":365954,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5278\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 825\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='825' max='825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [825/825 06:01, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.360800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.300200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.245500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.183400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.163900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.113000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.072800</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.057900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./training_output/checkpoint-500\n","Configuration saved in ./training_output/checkpoint-500/mexA3/adapter_config.json\n","Module weights saved in ./training_output/checkpoint-500/mexA3/pytorch_adapter.bin\n","Configuration saved in ./training_output/checkpoint-500/mexA3/head_config.json\n","Module weights saved in ./training_output/checkpoint-500/mexA3/pytorch_model_head.bin\n","Configuration saved in ./training_output/checkpoint-500/mexA3/head_config.json\n","Module weights saved in ./training_output/checkpoint-500/mexA3/pytorch_model_head.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=825, training_loss=0.18288082180601178, metrics={'train_runtime': 365.227, 'train_samples_per_second': 72.256, 'train_steps_per_second': 2.259, 'total_flos': 1758574969427640.0, 'train_loss': 0.18288082180601178, 'epoch': 5.0})"]},"metadata":{},"execution_count":14}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"556dae6d","metadata":{"id":"556dae6d","outputId":"4777d7ed-7b34-4c0c-afd3-8c4ea9f8d661","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1666145740341,"user_tz":300,"elapsed":3634,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 587\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19/19 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.37353992462158203,\n"," 'eval_acc': 0.9114139693356048,\n"," 'eval_runtime': 4.2694,\n"," 'eval_samples_per_second': 137.491,\n"," 'eval_steps_per_second': 4.45,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":15}],"source":["trainer.evaluate()"]},{"cell_type":"code","source":["model.save_adapter(\"weights\", \"mexA3\")"],"metadata":{"id":"xXm9iIfu_a8U"},"id":"xXm9iIfu_a8U","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qxj62t7xMD3_"},"id":"qxj62t7xMD3_","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Otro"],"metadata":{"id":"hX5_VHmxMFEO"},"id":"hX5_VHmxMFEO"},{"cell_type":"code","source":["data = [1, 2]\n","\n","other = list(data)"],"metadata":{"id":"Tx04iUDMMED2","executionInfo":{"status":"ok","timestamp":1670611301002,"user_tz":360,"elapsed":869,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"Tx04iUDMMED2","execution_count":2,"outputs":[]},{"cell_type":"code","source":["other[0] = 0\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SxA9QCo3MOmq","executionInfo":{"status":"ok","timestamp":1670611306543,"user_tz":360,"elapsed":1048,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"e0ca3a81-c3c7-46c5-a9f8-7a7ebf88dc3c"},"id":"SxA9QCo3MOmq","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["inputs = ['nodejs', 'reactjs', 'vuejs']\n","\n","for i in inputs:\n","  inputs.append(i.upper())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"Ewu-sJtNMX_B","executionInfo":{"status":"error","timestamp":1670611384380,"user_tz":360,"elapsed":14621,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"f9409ba6-e140-4f6f-e77e-33b6fcc1fd3e"},"id":"Ewu-sJtNMX_B","execution_count":4,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f396f5f53484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\"hola to TURING\".capitalize()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"_RpY0PnIMnnz","executionInfo":{"status":"ok","timestamp":1670611431729,"user_tz":360,"elapsed":3,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"24dbd49b-ac7b-4b47-9e70-555045cea15a"},"id":"_RpY0PnIMnnz","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hola to turing'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["z = set('abc')"],"metadata":{"id":"vZ0xLPHhMyT0","executionInfo":{"status":"ok","timestamp":1670611476766,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"vZ0xLPHhMyT0","execution_count":8,"outputs":[]},{"cell_type":"code","source":["z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zO_fN3HNB32","executionInfo":{"status":"ok","timestamp":1670611480005,"user_tz":360,"elapsed":870,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"913e7e91-e57d-43f3-faa9-8b01bc9a0154"},"id":"7zO_fN3HNB32","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a', 'b', 'c'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["l = [1, 2, 3]\n","m = map(lambda x: 2**x, l)"],"metadata":{"id":"Fyw7hHrzNCKm","executionInfo":{"status":"ok","timestamp":1670611637131,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"Fyw7hHrzNCKm","execution_count":10,"outputs":[]},{"cell_type":"code","source":["list(m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLlWOC4ENpBa","executionInfo":{"status":"ok","timestamp":1670611646730,"user_tz":360,"elapsed":399,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"98faef93-c526-4b58-bb54-a63208c19c28"},"id":"aLlWOC4ENpBa","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 8]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def f(x):\n","  x = 2return x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"_960TNLNNpm7","executionInfo":{"status":"error","timestamp":1670619808670,"user_tz":360,"elapsed":5,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"d4e71b18-e1cf-4649-be02-e2914ed1df11"},"id":"_960TNLNNpm7","execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d9f4d2281074>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    x = 2return x\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["i = 1\n","l = [2, 3]\n","while i in l:\n","  print(1) "],"metadata":{"id":"s4FvHDLcsz9P","executionInfo":{"status":"ok","timestamp":1670619971168,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"s4FvHDLcsz9P","execution_count":2,"outputs":[]},{"cell_type":"code","source":["l1 = [1, 2, 3, 4]\n","l2 = [5, 6, 7]\n"],"metadata":{"id":"IHA01a0Ztbwc","executionInfo":{"status":"ok","timestamp":1670620121395,"user_tz":360,"elapsed":1,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"IHA01a0Ztbwc","execution_count":7,"outputs":[]},{"cell_type":"code","source":["l1.extend(l2)"],"metadata":{"id":"kVQH5Abct3Fg","executionInfo":{"status":"ok","timestamp":1670620134539,"user_tz":360,"elapsed":1,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"kVQH5Abct3Fg","execution_count":10,"outputs":[]},{"cell_type":"code","source":["l1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEeiUqsOt3q4","executionInfo":{"status":"ok","timestamp":1670620139199,"user_tz":360,"elapsed":320,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"c4ea49b8-6ce5-481f-f04a-4592187983b3"},"id":"jEeiUqsOt3q4","execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5, 6, 7]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["def func1():\n","  x = 50\n","  return x "],"metadata":{"id":"RqhZEazyuEmx","executionInfo":{"status":"ok","timestamp":1670620219969,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}}},"id":"RqhZEazyuEmx","execution_count":14,"outputs":[]},{"cell_type":"code","source":["func1()\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"0SqG2UpuuSlT","executionInfo":{"status":"error","timestamp":1670620229918,"user_tz":360,"elapsed":305,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"622caf4e-458d-48c1-c6b8-5441e64a74c5"},"id":"0SqG2UpuuSlT","execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f0180949fa1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfunc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","source":["l = [1, 2, 3, 5]\n","\n","l.append(3, 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"my31mh3kuaxV","executionInfo":{"status":"error","timestamp":1670620384189,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"431fa9aa-47a7-48a3-e1bf-75fa884d7a89"},"id":"my31mh3kuaxV","execution_count":18,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-50bfa7ca4dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"]}]},{"cell_type":"code","source":["\"caca\".join([\"c\", \"a\", \"b\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rHSBcgoGu69J","executionInfo":{"status":"ok","timestamp":1670620457357,"user_tz":360,"elapsed":3,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"962d5749-22e0-40b4-b1ad-06a7aec19270"},"id":"rHSBcgoGu69J","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ccacaacacab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["'The {0} side {1} {2}'.format('bright', 'of', 'life')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"pio2vXHtu7WZ","executionInfo":{"status":"ok","timestamp":1670620511192,"user_tz":360,"elapsed":4,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"5e8957cc-11d0-467e-a6f9-c4f43d657364"},"id":"pio2vXHtu7WZ","execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The bright side of life'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import re\n","\n","result = re.findall('Welcome to Turing', 'Welcome', 1)\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHk6hZeGvc_l","executionInfo":{"status":"ok","timestamp":1670620612026,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"4b9844ab-21bb-4d94-a3be-61777e3bb4c0"},"id":"zHk6hZeGvc_l","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","source":["t = '%(a)s %(b)s %(c)s'\n","print(t%dict(a='Welcome', b='to', c='Turing'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Ooy9rTfv4OJ","executionInfo":{"status":"ok","timestamp":1670620776312,"user_tz":360,"elapsed":3,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"ce14e97f-988d-455d-af29-4b6976e33c0a"},"id":"5Ooy9rTfv4OJ","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to Turing\n"]}]},{"cell_type":"code","source":["dict(a='Welcome', b='to', c='Turing')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pm8eRB70wgS1","executionInfo":{"status":"ok","timestamp":1670620804991,"user_tz":360,"elapsed":3,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"ec5c161c-2f45-4e00-d75c-c99fd8d8ad44"},"id":"Pm8eRB70wgS1","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a': 'Welcome', 'b': 'to', 'c': 'Turing'}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["l.pop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vBS2duswnMW","executionInfo":{"status":"ok","timestamp":1670621010799,"user_tz":360,"elapsed":329,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"5d3bc3a0-3559-454f-dbc1-ce754e88e393"},"id":"2vBS2duswnMW","execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["l"],"metadata":{"id":"58cWnj5UxX_0","executionInfo":{"status":"ok","timestamp":1670621013371,"user_tz":360,"elapsed":2,"user":{"displayName":"Jorge Miguel Valles Silva","userId":"04945259833804033090"}},"outputId":"0c01d4d1-fb12-48b1-b2ec-a2fa7e06b684","colab":{"base_uri":"https://localhost:8080/"}},"id":"58cWnj5UxX_0","execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"gyfaf25ixaDU"},"id":"gyfaf25ixaDU","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"85d0faef4adf455380bad14a3131b325":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad5db37da70c4d01ba59e24503399176","IPY_MODEL_4753eb1187f8455b891b3b544c40bb1a","IPY_MODEL_42c6777a177a47a0b3989159ea8b1272"],"layout":"IPY_MODEL_326b02c8d0f047e4afd2112fd490fd11"}},"ad5db37da70c4d01ba59e24503399176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13682ba38f3c467cbd7fc4bdd3361dee","placeholder":"​","style":"IPY_MODEL_23d40e8793204e059d2f8abd32fd2cf4","value":"Downloading tokenizer_config.json: 100%"}},"4753eb1187f8455b891b3b544c40bb1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca848dfefc164cffab3e9167bed53ed7","max":319,"min":0,"orientation":"horizontal","style":"IPY_MODEL_268f3a01442b4ca0ac9d34ceace67abc","value":319}},"42c6777a177a47a0b3989159ea8b1272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a97dda7c3cc49a8b8027cbdc6740eb0","placeholder":"​","style":"IPY_MODEL_2fddb6db0aba440e8d123fecec44b414","value":" 319/319 [00:00&lt;00:00, 10.5kB/s]"}},"326b02c8d0f047e4afd2112fd490fd11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13682ba38f3c467cbd7fc4bdd3361dee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d40e8793204e059d2f8abd32fd2cf4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca848dfefc164cffab3e9167bed53ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"268f3a01442b4ca0ac9d34ceace67abc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a97dda7c3cc49a8b8027cbdc6740eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fddb6db0aba440e8d123fecec44b414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"428be957f35849178b007e15a8dc0ff5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13098c6d454844ac839b6488dc456b02","IPY_MODEL_6f7707a781244d2fa45e950619bd6c9c","IPY_MODEL_239bc939116d4f76bd9ee0edf8e0e89b"],"layout":"IPY_MODEL_1b2c33a654fe4e66a7e78f53f53f8fb1"}},"13098c6d454844ac839b6488dc456b02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feb8ed226bcc4d5b9d783ec709cbd587","placeholder":"​","style":"IPY_MODEL_383847178bfd44b9a73f3af4af38f5e9","value":"Downloading tokenizer.json: 100%"}},"6f7707a781244d2fa45e950619bd6c9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b0697bf78c4b7b9233f0202577ae50","max":828447,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b93ef335afe4439bbe76375d92dcc31","value":828447}},"239bc939116d4f76bd9ee0edf8e0e89b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbeaf5e149814ceda60909b9f8c1d91b","placeholder":"​","style":"IPY_MODEL_08ebe1f7dd1444879ee0d055cf111442","value":" 809k/809k [00:01&lt;00:00, 711kB/s]"}},"1b2c33a654fe4e66a7e78f53f53f8fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb8ed226bcc4d5b9d783ec709cbd587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"383847178bfd44b9a73f3af4af38f5e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b0697bf78c4b7b9233f0202577ae50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b93ef335afe4439bbe76375d92dcc31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbeaf5e149814ceda60909b9f8c1d91b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08ebe1f7dd1444879ee0d055cf111442":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a1e9c3c181448fcae101a45b0a78c2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_819ee85041b24d2dab4ae7d3e835f624","IPY_MODEL_26e9f2fe86b947f38f844cdbfcdf278a","IPY_MODEL_3a142204fc1144c7b18c898123296bc1"],"layout":"IPY_MODEL_e8a4093d6ae446caa295d49fc45065df"}},"819ee85041b24d2dab4ae7d3e835f624":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c590549070f41da84e555e0a19e4cd8","placeholder":"​","style":"IPY_MODEL_5b738913fc4f4db1b53f9c85c497ec54","value":"Downloading special_tokens_map.json: 100%"}},"26e9f2fe86b947f38f844cdbfcdf278a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e65dd185ea4747a3b61ce3096ce8a354","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d422c7c15859441683d8dcd43b44267f","value":150}},"3a142204fc1144c7b18c898123296bc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a89d4c32c3d44d209373daef7c222a6e","placeholder":"​","style":"IPY_MODEL_03948ec542a443f4b050695443eee569","value":" 150/150 [00:00&lt;00:00, 4.86kB/s]"}},"e8a4093d6ae446caa295d49fc45065df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c590549070f41da84e555e0a19e4cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b738913fc4f4db1b53f9c85c497ec54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e65dd185ea4747a3b61ce3096ce8a354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d422c7c15859441683d8dcd43b44267f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a89d4c32c3d44d209373daef7c222a6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03948ec542a443f4b050695443eee569":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1953d9d4c464000b0dfec3fd8b66304":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d18d11987184fe28cae708448c6dbfa","IPY_MODEL_f572333da8ac4278997b9372ab2e1932","IPY_MODEL_31d47c29f763463b9707146d9b491acc"],"layout":"IPY_MODEL_6acb0bae6c314a4f8c69abc506a41a17"}},"9d18d11987184fe28cae708448c6dbfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e71849750e8b465d939b3273665a4080","placeholder":"​","style":"IPY_MODEL_f3e8e8f4fb4343868d27c746d8c7067c","value":"Downloading config.json: 100%"}},"f572333da8ac4278997b9372ab2e1932":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daaa9b3d39f5450c9476960cd6c562c6","max":677,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2520436aa754218839173ae6f6d5e1f","value":677}},"31d47c29f763463b9707146d9b491acc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8404632412c1400fa678d791f28137c3","placeholder":"​","style":"IPY_MODEL_3ad4dd9eaef544ecbe9ef5e42be1b93a","value":" 677/677 [00:00&lt;00:00, 20.4kB/s]"}},"6acb0bae6c314a4f8c69abc506a41a17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e71849750e8b465d939b3273665a4080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e8e8f4fb4343868d27c746d8c7067c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daaa9b3d39f5450c9476960cd6c562c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2520436aa754218839173ae6f6d5e1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8404632412c1400fa678d791f28137c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ad4dd9eaef544ecbe9ef5e42be1b93a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e080df9208474471956cac43ed054af0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88df4bb14317408387f6d5fe41b99290","IPY_MODEL_761127450eaf46528199ba82841d838c","IPY_MODEL_b30c938b336d4bf4b40b7f05a839ba80"],"layout":"IPY_MODEL_74030870d8e34811acbf685515bd0c8c"}},"88df4bb14317408387f6d5fe41b99290":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e51ca81da6fe4fffb96b2c17d15a2bd2","placeholder":"​","style":"IPY_MODEL_161b24c20e6b4694b682a7f0e0cc0085","value":"Downloading pytorch_model.bin: 100%"}},"761127450eaf46528199ba82841d838c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0663f9f459414d4fa4bcb08539941a18","max":435341035,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba7dd565ccf944ffa3b0c23559a7f313","value":435341035}},"b30c938b336d4bf4b40b7f05a839ba80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbdc455551124373ba7eab5fb0796b47","placeholder":"​","style":"IPY_MODEL_2745d2c26cf545428661d86e030a843e","value":" 415M/415M [00:42&lt;00:00, 15.3MB/s]"}},"74030870d8e34811acbf685515bd0c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e51ca81da6fe4fffb96b2c17d15a2bd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"161b24c20e6b4694b682a7f0e0cc0085":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0663f9f459414d4fa4bcb08539941a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba7dd565ccf944ffa3b0c23559a7f313":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbdc455551124373ba7eab5fb0796b47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2745d2c26cf545428661d86e030a843e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}